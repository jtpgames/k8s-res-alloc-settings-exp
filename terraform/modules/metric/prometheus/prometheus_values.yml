server:
  strategy:
    type: RollingUpdate
    
  resources:
    limits:
      cpu: 800m
      memory: 1600Mi
    requests:
      cpu: 300m
      memory: 512Mi

  nodeSelector:
    kubernetes.io/hostname: ${node}

  global:
    scrape_interval: 5s
    scrape_timeout: 5s
    evaluation_interval: 5s

alertmanager:
  enabled: false

kube-state-metrics:
  rbac:
    extraRules:
      - apiGroups: [ "autoscaling.k8s.io" ]
        resources: [ "verticalpodautoscalers" ]
        verbs: [ "list", "watch" ]
  customResourceState:
    enabled: true
    config:
      kind: CustomResourceStateMetrics
      spec:
        resources:
          - groupVersionKind:
              group: autoscaling.k8s.io
              kind: "VerticalPodAutoscaler"
              version: "v1"
            labelsFromPath:
              verticalpodautoscaler: [metadata, name]
              namespace: [metadata, namespace]
              target_api_version: [spec, targetRef, apiVersion]
              target_kind: [spec, targetRef, kind]
              target_name: [spec, targetRef, name]
            metrics:
              # Labels
              - name: "verticalpodautoscaler_labels"
                help: "VPA container recommendations. Kubernetes labels converted to Prometheus labels"
                each:
                  type: Info
                  info:
                    labelsFromPath:
                      name: [metadata, name]
              # Memory Information
              - name: "verticalpodautoscaler_status_recommendation_containerrecommendations_target"
                help: "VPA container recommendations for memory. Target resources the VerticalPodAutoscaler recommends for the container."
                each:
                  type: Gauge
                  gauge:
                    path: [status, recommendation, containerRecommendations]
                    valueFrom: [target, memory]
                    labelsFromPath:
                      container: [containerName]
                commonLabels:
                  resource: "memory"
                  unit: "byte"
              - name: "verticalpodautoscaler_status_recommendation_containerrecommendations_lowerbound"
                help: "VPA container recommendations for memory. Minimum resources the container can use before the VerticalPodAutoscaler updater evicts it"
                each:
                  type: Gauge
                  gauge:
                    path: [status, recommendation, containerRecommendations]
                    valueFrom: [lowerBound, memory]
                    labelsFromPath:
                      container: [containerName]
                commonLabels:
                  resource: "memory"
                  unit: "byte"
              - name: "verticalpodautoscaler_status_recommendation_containerrecommendations_upperbound"
                help: "VPA container recommendations for memory. Maximum resources the container can use before the VerticalPodAutoscaler updater evicts it"
                each:
                  type: Gauge
                  gauge:
                    path: [status, recommendation, containerRecommendations]
                    valueFrom: [upperBound, memory]
                    labelsFromPath:
                      container: [containerName]
                commonLabels:
                  resource: "memory"
                  unit: "byte"
              - name: "verticalpodautoscaler_status_recommendation_containerrecommendations_uncappedtarget"
                help: "VPA container recommendations for memory. Target resources the VerticalPodAutoscaler recommends for the container ignoring bounds"
                each:
                  type: Gauge
                  gauge:
                    path: [status, recommendation, containerRecommendations]
                    valueFrom: [uncappedTarget, memory]
                    labelsFromPath:
                      container: [containerName]
                commonLabels:
                  resource: "memory"
                  unit: "byte"
              # CPU Information
              - name: "verticalpodautoscaler_status_recommendation_containerrecommendations_target"
                help: "VPA container recommendations for cpu. Target resources the VerticalPodAutoscaler recommends for the container."
                each:
                  type: Gauge
                  gauge:
                    path: [status, recommendation, containerRecommendations]
                    valueFrom: [target, cpu]
                    labelsFromPath:
                      container: [containerName]
                commonLabels:
                  resource: "cpu"
                  unit: "core"
              - name: "verticalpodautoscaler_status_recommendation_containerrecommendations_lowerbound"
                help: "VPA container recommendations for cpu. Minimum resources the container can use before the VerticalPodAutoscaler updater evicts it"
                each:
                  type: Gauge
                  gauge:
                    path: [status, recommendation, containerRecommendations]
                    valueFrom: [lowerBound, cpu]
                    labelsFromPath:
                      container: [containerName]
                commonLabels:
                  resource: "cpu"
                  unit: "core"
              - name: "verticalpodautoscaler_status_recommendation_containerrecommendations_upperbound"
                help: "VPA container recommendations for cpu. Maximum resources the container can use before the VerticalPodAutoscaler updater evicts it"
                each:
                  type: Gauge
                  gauge:
                    path: [status, recommendation, containerRecommendations]
                    valueFrom: [upperBound, cpu]
                    labelsFromPath:
                      container: [containerName]
                commonLabels:
                  resource: "cpu"
                  unit: "core"
              - name: "verticalpodautoscaler_status_recommendation_containerrecommendations_uncappedtarget"
                help: "VPA container recommendations for cpu. Target resources the VerticalPodAutoscaler recommends for the container ignoring bounds"
                each:
                  type: Gauge
                  gauge:
                    path: [status, recommendation, containerRecommendations]
                    valueFrom: [uncappedTarget, cpu]
                    labelsFromPath:
                      container: [containerName]
                commonLabels:
                  resource: "cpu"
                  unit: "core"

  selfMonitor:
    enabled: true

  resources:
    limits:
      cpu: 200m
      memory: 128Mi
    requests:
      cpu: 50m
      memory: 32Mi

  nodeSelector:
    kubernetes.io/hostname: ${node}

prometheus-node-exporter:
  resources:
    limits:
      cpu: 200m
      memory: 50Mi
    requests:
      cpu: 100m
      memory: 30Mi

  nodeSelector:
    kubernetes.io/hostname: ${node}

prometheus-pushgateway:
  enabled: false

serverFiles:
  prometheus.yml:
    scrape_configs:
      - job_name: prometheus
        static_configs:
          - targets:
              - localhost:9090
            labels:
              exporter_namespace: metric
              exporter_pod: prometheus
              exporter_container: prometheus
              cluster: main

      # 8081 for self monitoring
      - job_name: kube-state-metrics
        honor_labels: true
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_namespace]
            regex: ^(${namespace})$
            action: keep
          - source_labels:
              [__meta_kubernetes_pod_label_app_kubernetes_io_component]
            regex: ^(metrics)$
            action: keep
          - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name]
            regex: ^(kube-state-metrics)$
            action: keep
          - source_labels: [__meta_kubernetes_pod_container_port_number]
            regex: ^(8080|8081)$
            action: keep

          - source_labels: [__meta_kubernetes_pod_container_name]
            regex: ^(linkerd-init|linkerd-proxy)$
            action: drop
          - source_labels: [__meta_kubernetes_namespace]
            target_label: exporter_namespace
          - source_labels: [__meta_kubernetes_pod_container_name]
            target_label: exporter_container
          - source_labels: [__meta_kubernetes_pod_name]
            target_label: exporter_pod
          - source_labels: [__meta_kubernetes_pod_node_name]
            target_label: exporter_node
          - source_labels: [__address__]
            action: replace
            regex: (.*)
            replacement: main
            target_label: cluster

      - job_name: ingress-nginx-controller
        honor_labels: true
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_namespace]
            regex: ^(ingress-nginx)$
            action: keep
          - source_labels:
              [__meta_kubernetes_pod_label_app_kubernetes_io_component]
            regex: ^(controller)$
            action: keep
          - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name]
            regex: ^(ingress-nginx)$
            action: keep
          - source_labels: [__meta_kubernetes_pod_container_port_number]
            regex: ^(10254)$
            action: keep

          - source_labels: [__meta_kubernetes_pod_container_name]
            regex: ^(linkerd-init|linkerd-proxy)$
            action: drop
          - source_labels: [__meta_kubernetes_namespace]
            target_label: exporter_namespace
          - source_labels: [__meta_kubernetes_pod_container_name]
            target_label: exporter_container
          - source_labels: [__meta_kubernetes_pod_name]
            target_label: exporter_pod
          - source_labels: [__meta_kubernetes_pod_node_name]
            target_label: exporter_node
          - source_labels: [__address__]
            action: replace
            regex: (.*)
            replacement: main
            target_label: cluster

      - job_name: node-exporter
        honor_labels: true
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_namespace]
            regex: ^(${namespace})$
            action: keep
          - source_labels:
              [__meta_kubernetes_pod_label_app_kubernetes_io_component]
            regex: ^(metrics)$
            action: keep
          - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name]
            regex: ^(prometheus-node-exporter)$
            action: keep
          - source_labels: [__meta_kubernetes_pod_container_port_number]
            regex: ^(9100)$
            action: keep

          - source_labels: [__meta_kubernetes_pod_container_name]
            regex: ^(linkerd-init|linkerd-proxy)$
            action: drop
          - source_labels: [__meta_kubernetes_namespace]
            target_label: exporter_namespace
          - source_labels: [__meta_kubernetes_pod_container_name]
            target_label: exporter_container
          - source_labels: [__meta_kubernetes_pod_name]
            target_label: exporter_pod
          - source_labels: [__meta_kubernetes_pod_node_name]
            target_label: exporter_node
          - source_labels: [__address__]
            action: replace
            regex: (.*)
            replacement: main
            target_label: cluster
          # for lens
          - source_labels: [__meta_kubernetes_pod_node_name]
            target_label: node

      - job_name: grafana
        honor_labels: true
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_namespace]
            regex: ^(${namespace})$
            action: keep
          - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name]
            regex: ^(grafana)$
            action: keep
          - source_labels: [__meta_kubernetes_pod_container_port_number]
            regex: ^(3000)$
            action: keep

          - source_labels: [__meta_kubernetes_pod_container_name]
            regex: ^(linkerd-init|linkerd-proxy)$
            action: drop
          - source_labels: [__meta_kubernetes_namespace]
            target_label: exporter_namespace
          - source_labels: [__meta_kubernetes_pod_container_name]
            target_label: exporter_container
          - source_labels: [__meta_kubernetes_pod_name]
            target_label: exporter_pod
          - source_labels: [__meta_kubernetes_pod_node_name]
            target_label: exporter_node
          - source_labels: [__address__]
            action: replace
            regex: (.*)
            replacement: main
            target_label: cluster

      - job_name: kubelet
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            regex: (.+)
            target_label: __metrics_path__
            replacement: /api/v1/nodes/$1/proxy/metrics
          - source_labels: [__address__]
            action: replace
            regex: (.*)
            replacement: main
            target_label: cluster
          - source_labels: [__address__]
            action: replace
            regex: (.*)
            replacement: /metrics
            target_label: metrics_path

      - job_name: kubelet-cadvisor
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            regex: (.+)
            target_label: __metrics_path__
            replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor
          - source_labels: [__address__]
            action: replace
            regex: (.*)
            replacement: main
            target_label: cluster
          - source_labels: [__address__]
            action: replace
            regex: (.*)
            replacement: /metrics/cadvisor
            target_label: metrics_path
          - source_labels: [job]
            action: replace
            regex: (.*)
            replacement: kubelet
            target_label: job

      - job_name: kubelet-probes
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            regex: (.+)
            target_label: __metrics_path__
            replacement: /api/v1/nodes/$1/proxy/metrics/probes
          - source_labels: [__address__]
            action: replace
            regex: (.*)
            replacement: main
            target_label: cluster
          - source_labels: [__address__]
            action: replace
            regex: (.*)
            replacement: /metrics/probes
            target_label: metrics_path
          - source_labels: [job]
            action: replace
            regex: (.*)
            replacement: kubelet
            target_label: job

      - job_name: apiserver
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        kubernetes_sd_configs:
          - role: endpoints
        relabel_configs:
          - action: keep
            regex: default;kubernetes;https
            source_labels:
              - __meta_kubernetes_namespace
              - __meta_kubernetes_service_name
              - __meta_kubernetes_endpoint_port_name
          - source_labels: [__address__]
            action: replace
            regex: (.*)
            replacement: main
            target_label: cluster

  recording_rules.yml:
    groups:
      - name: kube-apiserver-burnrate.rules
        rules:
          - expr: |
              (
                (
                  # too slow
                  sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[1d]))
                  -
                  (
                    (
                      sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[1d]))
                      or
                      vector(0)
                    )
                    +
                    sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[1d]))
                    +
                    sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[1d]))
                  )
                )
                +
                # errors
                sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[1d]))
              )
              /
              sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[1d]))
            labels:
              verb: read
            record: apiserver_request:burnrate1d
          - expr: |
              (
                (
                  # too slow
                  sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[1h]))
                  -
                  (
                    (
                      sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[1h]))
                      or
                      vector(0)
                    )
                    +
                    sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[1h]))
                    +
                    sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[1h]))
                  )
                )
                +
                # errors
                sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[1h]))
              )
              /
              sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[1h]))
            labels:
              verb: read
            record: apiserver_request:burnrate1h
          - expr: |
              (
                (
                  # too slow
                  sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[2h]))
                  -
                  (
                    (
                      sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[2h]))
                      or
                      vector(0)
                    )
                    +
                    sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[2h]))
                    +
                    sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[2h]))
                  )
                )
                +
                # errors
                sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[2h]))
              )
              /
              sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[2h]))
            labels:
              verb: read
            record: apiserver_request:burnrate2h
          - expr: |
              (
                (
                  # too slow
                  sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[30m]))
                  -
                  (
                    (
                      sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[30m]))
                      or
                      vector(0)
                    )
                    +
                    sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[30m]))
                    +
                    sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[30m]))
                  )
                )
                +
                # errors
                sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[30m]))
              )
              /
              sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[30m]))
            labels:
              verb: read
            record: apiserver_request:burnrate30m
          - expr: |
              (
                (
                  # too slow
                  sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[3d]))
                  -
                  (
                    (
                      sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[3d]))
                      or
                      vector(0)
                    )
                    +
                    sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[3d]))
                    +
                    sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[3d]))
                  )
                )
                +
                # errors
                sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[3d]))
              )
              /
              sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[3d]))
            labels:
              verb: read
            record: apiserver_request:burnrate3d
          - expr: |
              (
                (
                  # too slow
                  sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[5m]))
                  -
                  (
                    (
                      sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[5m]))
                      or
                      vector(0)
                    )
                    +
                    sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[5m]))
                    +
                    sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[5m]))
                  )
                )
                +
                # errors
                sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[5m]))
              )
              /
              sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[5m]))
            labels:
              verb: read
            record: apiserver_request:burnrate5m
          - expr: |
              (
                (
                  # too slow
                  sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[6h]))
                  -
                  (
                    (
                      sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[6h]))
                      or
                      vector(0)
                    )
                    +
                    sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[6h]))
                    +
                    sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[6h]))
                  )
                )
                +
                # errors
                sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[6h]))
              )
              /
              sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[6h]))
            labels:
              verb: read
            record: apiserver_request:burnrate6h
          - expr: |
              (
                (
                  # too slow
                  sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[1d]))
                  -
                  sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[1d]))
                )
                +
                sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[1d]))
              )
              /
              sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[1d]))
            labels:
              verb: write
            record: apiserver_request:burnrate1d
          - expr: |
              (
                (
                  # too slow
                  sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[1h]))
                  -
                  sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[1h]))
                )
                +
                sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[1h]))
              )
              /
              sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[1h]))
            labels:
              verb: write
            record: apiserver_request:burnrate1h
          - expr: |
              (
                (
                  # too slow
                  sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[2h]))
                  -
                  sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[2h]))
                )
                +
                sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[2h]))
              )
              /
              sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[2h]))
            labels:
              verb: write
            record: apiserver_request:burnrate2h
          - expr: |
              (
                (
                  # too slow
                  sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[30m]))
                  -
                  sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[30m]))
                )
                +
                sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[30m]))
              )
              /
              sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[30m]))
            labels:
              verb: write
            record: apiserver_request:burnrate30m
          - expr: |
              (
                (
                  # too slow
                  sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[3d]))
                  -
                  sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[3d]))
                )
                +
                sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[3d]))
              )
              /
              sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[3d]))
            labels:
              verb: write
            record: apiserver_request:burnrate3d
          - expr: |
              (
                (
                  # too slow
                  sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[5m]))
                  -
                  sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[5m]))
                )
                +
                sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[5m]))
              )
              /
              sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[5m]))
            labels:
              verb: write
            record: apiserver_request:burnrate5m
          - expr: |
              (
                (
                  # too slow
                  sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[6h]))
                  -
                  sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[6h]))
                )
                +
                sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[6h]))
              )
              /
              sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[6h]))
            labels:
              verb: write
            record: apiserver_request:burnrate6h

      - name: kube-apiserver-histogram.rules
        rules:
          - expr: |
              histogram_quantile(0.99, sum by (cluster, le, resource) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[5m]))) > 0
            labels:
              quantile: "0.99"
              verb: read
            record: cluster_quantile:apiserver_request_slo_duration_seconds:histogram_quantile
          - expr: |
              histogram_quantile(0.99, sum by (cluster, le, resource) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[5m]))) > 0
            labels:
              quantile: "0.99"
              verb: write
            record: cluster_quantile:apiserver_request_slo_duration_seconds:histogram_quantile

      - name: kube-apiserver-availability.rules
        rules:
          - expr: |
              avg_over_time(code_verb:apiserver_request_total:increase1h[30d]) * 24 * 30
            record: code_verb:apiserver_request_total:increase30d
          - expr: |
              sum by (cluster, code) (code_verb:apiserver_request_total:increase30d{verb=~"LIST|GET"})
            labels:
              verb: read
            record: code:apiserver_request_total:increase30d
          - expr: |
              sum by (cluster, code) (code_verb:apiserver_request_total:increase30d{verb=~"POST|PUT|PATCH|DELETE"})
            labels:
              verb: write
            record: code:apiserver_request_total:increase30d
          - expr: |
              sum by (cluster, verb, scope) (increase(apiserver_request_slo_duration_seconds_count{job="apiserver"}[1h]))
            record: cluster_verb_scope:apiserver_request_slo_duration_seconds_count:increase1h
          - expr: |
              sum by (cluster, verb, scope) (avg_over_time(cluster_verb_scope:apiserver_request_slo_duration_seconds_count:increase1h[30d]) * 24 * 30)
            record: cluster_verb_scope:apiserver_request_slo_duration_seconds_count:increase30d
          - expr: |
              sum by (cluster, verb, scope, le) (increase(apiserver_request_slo_duration_seconds_bucket[1h]))
            record: cluster_verb_scope_le:apiserver_request_slo_duration_seconds_bucket:increase1h
          - expr: |
              sum by (cluster, verb, scope, le) (avg_over_time(cluster_verb_scope_le:apiserver_request_slo_duration_seconds_bucket:increase1h[30d]) * 24 * 30)
            record: cluster_verb_scope_le:apiserver_request_slo_duration_seconds_bucket:increase30d
          - expr: |
              1 - (
                (
                  # write too slow
                  sum by (cluster) (cluster_verb_scope:apiserver_request_slo_duration_seconds_count:increase30d{verb=~"POST|PUT|PATCH|DELETE"})
                  -
                  sum by (cluster) (cluster_verb_scope_le:apiserver_request_slo_duration_seconds_bucket:increase30d{verb=~"POST|PUT|PATCH|DELETE",le="1"})
                ) +
                (
                  # read too slow
                  sum by (cluster) (cluster_verb_scope:apiserver_request_slo_duration_seconds_count:increase30d{verb=~"LIST|GET"})
                  -
                  (
                    (
                      sum by (cluster) (cluster_verb_scope_le:apiserver_request_slo_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope=~"resource|",le="1"})
                      or
                      vector(0)
                    )
                    +
                    sum by (cluster) (cluster_verb_scope_le:apiserver_request_slo_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="namespace",le="5"})
                    +
                    sum by (cluster) (cluster_verb_scope_le:apiserver_request_slo_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="cluster",le="30"})
                  )
                ) +
                # errors
                sum by (cluster) (code:apiserver_request_total:increase30d{code=~"5.."} or vector(0))
              )
              /
              sum by (cluster) (code:apiserver_request_total:increase30d)
            labels:
              verb: all
            record: apiserver_request:availability30d
          - expr: |
              1 - (
                sum by (cluster) (cluster_verb_scope:apiserver_request_slo_duration_seconds_count:increase30d{verb=~"LIST|GET"})
                -
                (
                  # too slow
                  (
                    sum by (cluster) (cluster_verb_scope_le:apiserver_request_slo_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope=~"resource|",le="1"})
                    or
                    vector(0)
                  )
                  +
                  sum by (cluster) (cluster_verb_scope_le:apiserver_request_slo_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="namespace",le="5"})
                  +
                  sum by (cluster) (cluster_verb_scope_le:apiserver_request_slo_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="cluster",le="30"})
                )
                +
                # errors
                sum by (cluster) (code:apiserver_request_total:increase30d{verb="read",code=~"5.."} or vector(0))
              )
              /
              sum by (cluster) (code:apiserver_request_total:increase30d{verb="read"})
            labels:
              verb: read
            record: apiserver_request:availability30d
          - expr: |
              1 - (
                (
                  # too slow
                  sum by (cluster) (cluster_verb_scope:apiserver_request_slo_duration_seconds_count:increase30d{verb=~"POST|PUT|PATCH|DELETE"})
                  -
                  sum by (cluster) (cluster_verb_scope_le:apiserver_request_slo_duration_seconds_bucket:increase30d{verb=~"POST|PUT|PATCH|DELETE",le="1"})
                )
                +
                # errors
                sum by (cluster) (code:apiserver_request_total:increase30d{verb="write",code=~"5.."} or vector(0))
              )
              /
              sum by (cluster) (code:apiserver_request_total:increase30d{verb="write"})
            labels:
              verb: write
            record: apiserver_request:availability30d
          - expr: |
              sum by (cluster,code,resource) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[5m]))
            labels:
              verb: read
            record: code_resource:apiserver_request_total:rate5m
          - expr: |
              sum by (cluster,code,resource) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[5m]))
            labels:
              verb: write
            record: code_resource:apiserver_request_total:rate5m
          - expr: |
              sum by (cluster, code, verb) (increase(apiserver_request_total{job="apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"2.."}[1h]))
            record: code_verb:apiserver_request_total:increase1h
          - expr: |
              sum by (cluster, code, verb) (increase(apiserver_request_total{job="apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"3.."}[1h]))
            record: code_verb:apiserver_request_total:increase1h
          - expr: |
              sum by (cluster, code, verb) (increase(apiserver_request_total{job="apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"4.."}[1h]))
            record: code_verb:apiserver_request_total:increase1h
          - expr: |
              sum by (cluster, code, verb) (increase(apiserver_request_total{job="apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"5.."}[1h]))
            record: code_verb:apiserver_request_total:increase1h

      - name: k8s.rules
        rules:
          - expr: |
              sum by (cluster, namespace, pod, container) (
                irate(container_cpu_usage_seconds_total{job="kubelet", metrics_path="/metrics/cadvisor", image!=""}[5m])
              ) * on (cluster, namespace, pod) group_left(node) topk by (cluster, namespace, pod) (
                1, max by(cluster, namespace, pod, node) (kube_pod_info{node!=""})
              )
            record: node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate
          - expr: |
              container_memory_working_set_bytes{job="kubelet", metrics_path="/metrics/cadvisor", image!=""}
              * on (cluster, namespace, pod) group_left(node) topk by(cluster, namespace, pod) (1,
                max by(cluster, namespace, pod, node) (kube_pod_info{node!=""})
              )
            record: node_namespace_pod_container:container_memory_working_set_bytes
          - expr: |
              container_memory_rss{job="kubelet", metrics_path="/metrics/cadvisor", image!=""}
              * on (cluster, namespace, pod) group_left(node) topk by(cluster, namespace, pod) (1,
                max by(cluster, namespace, pod, node) (kube_pod_info{node!=""})
              )
            record: node_namespace_pod_container:container_memory_rss
          - expr: |
              container_memory_cache{job="kubelet", metrics_path="/metrics/cadvisor", image!=""}
              * on (cluster, namespace, pod) group_left(node) topk by(cluster, namespace, pod) (1,
                max by(cluster, namespace, pod, node) (kube_pod_info{node!=""})
              )
            record: node_namespace_pod_container:container_memory_cache
          - expr: |
              container_memory_swap{job="kubelet", metrics_path="/metrics/cadvisor", image!=""}
              * on (cluster, namespace, pod) group_left(node) topk by(cluster, namespace, pod) (1,
                max by(cluster, namespace, pod, node) (kube_pod_info{node!=""})
              )
            record: node_namespace_pod_container:container_memory_swap
          - expr: |
              kube_pod_container_resource_requests{resource="memory",job="kube-state-metrics"} * on (namespace, pod, cluster)
              group_left() max by (namespace, pod, cluster) (
                (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
              )
            record: cluster:namespace:pod_memory:active:kube_pod_container_resource_requests
          - expr: |
              sum by (namespace, cluster) (
                  sum by (namespace, pod, cluster) (
                      max by (namespace, pod, container, cluster) (
                        kube_pod_container_resource_requests{resource="memory",job="kube-state-metrics"}
                      ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
                        kube_pod_status_phase{phase=~"Pending|Running"} == 1
                      )
                  )
              )
            record: namespace_memory:kube_pod_container_resource_requests:sum
          - expr: |
              kube_pod_container_resource_requests{resource="cpu",job="kube-state-metrics"} * on (namespace, pod, cluster)
              group_left() max by (namespace, pod, cluster) (
                (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
              )
            record: cluster:namespace:pod_cpu:active:kube_pod_container_resource_requests
          - expr: |
              sum by (namespace, cluster) (
                  sum by (namespace, pod, cluster) (
                      max by (namespace, pod, container, cluster) (
                        kube_pod_container_resource_requests{resource="cpu",job="kube-state-metrics"}
                      ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
                        kube_pod_status_phase{phase=~"Pending|Running"} == 1
                      )
                  )
              )
            record: namespace_cpu:kube_pod_container_resource_requests:sum
          - expr: |
              kube_pod_container_resource_limits{resource="memory",job="kube-state-metrics"} * on (namespace, pod, cluster)
              group_left() max by (namespace, pod, cluster) (
                (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
              )
            record: cluster:namespace:pod_memory:active:kube_pod_container_resource_limits
          - expr: |
              sum by (namespace, cluster) (
                  sum by (namespace, pod, cluster) (
                      max by (namespace, pod, container, cluster) (
                        kube_pod_container_resource_limits{resource="memory",job="kube-state-metrics"}
                      ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
                        kube_pod_status_phase{phase=~"Pending|Running"} == 1
                      )
                  )
              )
            record: namespace_memory:kube_pod_container_resource_limits:sum
          - expr: |
              kube_pod_container_resource_limits{resource="cpu",job="kube-state-metrics"} * on (namespace, pod, cluster)
              group_left() max by (namespace, pod, cluster) (
              (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
              )
            record: cluster:namespace:pod_cpu:active:kube_pod_container_resource_limits
          - expr: |
              sum by (namespace, cluster) (
                  sum by (namespace, pod, cluster) (
                      max by (namespace, pod, container, cluster) (
                        kube_pod_container_resource_limits{resource="cpu",job="kube-state-metrics"}
                      ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
                        kube_pod_status_phase{phase=~"Pending|Running"} == 1
                      )
                  )
              )
            record: namespace_cpu:kube_pod_container_resource_limits:sum
          - expr: |
              max by (cluster, namespace, workload, pod) (
                label_replace(
                  label_replace(
                    kube_pod_owner{job="kube-state-metrics", owner_kind="ReplicaSet"},
                    "replicaset", "$1", "owner_name", "(.*)"
                  ) * on(replicaset, namespace) group_left(owner_name) topk by(replicaset, namespace) (
                    1, max by (replicaset, namespace, owner_name) (
                      kube_replicaset_owner{job="kube-state-metrics"}
                    )
                  ),
                  "workload", "$1", "owner_name", "(.*)"
                )
              )
            labels:
              workload_type: deployment
            record: namespace_workload_pod:kube_pod_owner:relabel
          - expr: |
              max by (cluster, namespace, workload, pod) (
                label_replace(
                  kube_pod_owner{job="kube-state-metrics", owner_kind="DaemonSet"},
                  "workload", "$1", "owner_name", "(.*)"
                )
              )
            labels:
              workload_type: daemonset
            record: namespace_workload_pod:kube_pod_owner:relabel
          - expr: |
              max by (cluster, namespace, workload, pod) (
                label_replace(
                  kube_pod_owner{job="kube-state-metrics", owner_kind="StatefulSet"},
                  "workload", "$1", "owner_name", "(.*)"
                )
              )
            labels:
              workload_type: statefulset
            record: namespace_workload_pod:kube_pod_owner:relabel
          - expr: |
              max by (cluster, namespace, workload, pod) (
                label_replace(
                  kube_pod_owner{job="kube-state-metrics", owner_kind="Job"},
                  "workload", "$1", "owner_name", "(.*)"
                )
              )
            labels:
              workload_type: job
            record: namespace_workload_pod:kube_pod_owner:relabel

      - name: node.rules
        rules:
          - expr: |
              topk by(cluster, namespace, pod) (1,
                max by (cluster, node, namespace, pod) (
                  label_replace(kube_pod_info{job="kube-state-metrics",node!=""}, "pod", "$1", "pod", "(.*)")
              ))
            record: "node_namespace_pod:kube_pod_info:"
          - expr: |
              count by (cluster, node) (
                node_cpu_seconds_total{mode="idle",job="node-exporter"}
                * on (namespace, pod) group_left(node)
                topk by(namespace, pod) (1, node_namespace_pod:kube_pod_info:)
              )
            record: node:node_num_cpu:sum
          - expr: |
              sum(
                node_memory_MemAvailable_bytes{job="node-exporter"} or
                (
                  node_memory_Buffers_bytes{job="node-exporter"} +
                  node_memory_Cached_bytes{job="node-exporter"} +
                  node_memory_MemFree_bytes{job="node-exporter"} +
                  node_memory_Slab_bytes{job="node-exporter"}
                )
              ) by (cluster)
            record: :node_memory_MemAvailable_bytes:sum
          - expr: |
              avg by (cluster, node) (
                sum without (mode) (
                  rate(node_cpu_seconds_total{mode!="idle",mode!="iowait",mode!="steal",job="node-exporter"}[5m])
                )
              )
            record: node:node_cpu_utilization:ratio_rate5m
          - expr: |
              avg by (cluster) (
                node:node_cpu_utilization:ratio_rate5m
              )
            record: cluster:node_cpu:ratio_rate5m

      - name: kubelet.rules
        rules:
          - expr: |
              histogram_quantile(0.99, sum(rate(kubelet_pleg_relist_duration_seconds_bucket{job="kubelet", metrics_path="/metrics"}[5m])) by (cluster, instance, le) * on(cluster, instance) group_left(node) kubelet_node_name{job="kubelet", metrics_path="/metrics"})
            labels:
              quantile: "0.99"
            record: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile
          - expr: |
              histogram_quantile(0.9, sum(rate(kubelet_pleg_relist_duration_seconds_bucket{job="kubelet", metrics_path="/metrics"}[5m])) by (cluster, instance, le) * on(cluster, instance) group_left(node) kubelet_node_name{job="kubelet", metrics_path="/metrics"})
            labels:
              quantile: "0.9"
            record: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile
          - expr: |
              histogram_quantile(0.5, sum(rate(kubelet_pleg_relist_duration_seconds_bucket{job="kubelet", metrics_path="/metrics"}[5m])) by (cluster, instance, le) * on(cluster, instance) group_left(node) kubelet_node_name{job="kubelet", metrics_path="/metrics"})
            labels:
              quantile: "0.5"
            record: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile

      - name: kube-prometheus-node-recording.rules
        rules:
          - expr:
              sum(rate(node_cpu_seconds_total{mode!="idle",mode!="iowait",mode!="steal"}[3m]))
              BY (instance)
            record: instance:node_cpu:rate:sum
          - expr: sum(rate(node_network_receive_bytes_total[3m])) BY (instance)
            record: instance:node_network_receive_bytes:rate:sum
          - expr: sum(rate(node_network_transmit_bytes_total[3m])) BY (instance)
            record: instance:node_network_transmit_bytes:rate:sum
          - expr:
              sum(rate(node_cpu_seconds_total{mode!="idle",mode!="iowait",mode!="steal"}[5m]))
              WITHOUT (cpu, mode) / ON(instance) GROUP_LEFT() count(sum(node_cpu_seconds_total)
              BY (instance, cpu)) BY (instance)
            record: instance:node_cpu:ratio
          - expr: sum(rate(node_cpu_seconds_total{mode!="idle",mode!="iowait",mode!="steal"}[5m]))
            record: cluster:node_cpu:sum_rate5m
          - expr:
              cluster:node_cpu:sum_rate5m / count(sum(node_cpu_seconds_total) BY (instance,
              cpu))
            record: cluster:node_cpu:ratio

      - name: kube-prometheus-general.rules
        rules:
          - expr: count without(instance, pod, node) (up == 1)
            record: count:up1
          - expr: count without(instance, pod, node) (up == 0)
            record: count:up0

      - name: node-exporter.rules
        rules:
          - expr: |
              count without (cpu, mode) (
                node_cpu_seconds_total{job="node-exporter",mode="idle"}
              )
            record: instance:node_num_cpu:sum
          - expr: |
              1 - avg without (cpu) (
                sum without (mode) (rate(node_cpu_seconds_total{job="node-exporter", mode=~"idle|iowait|steal"}[5m]))
              )
            record: instance:node_cpu_utilisation:rate5m
          - expr: |
              (
                node_load1{job="node-exporter"}
              /
                instance:node_num_cpu:sum{job="node-exporter"}
              )
            record: instance:node_load1_per_cpu:ratio
          - expr: |
              1 - (
                (
                  node_memory_MemAvailable_bytes{job="node-exporter"}
                  or
                  (
                    node_memory_Buffers_bytes{job="node-exporter"}
                    +
                    node_memory_Cached_bytes{job="node-exporter"}
                    +
                    node_memory_MemFree_bytes{job="node-exporter"}
                    +
                    node_memory_Slab_bytes{job="node-exporter"}
                  )
                )
              /
                node_memory_MemTotal_bytes{job="node-exporter"}
              )
            record: instance:node_memory_utilisation:ratio
          - expr: |
              rate(node_vmstat_pgmajfault{job="node-exporter"}[5m])
            record: instance:node_vmstat_pgmajfault:rate5m
          - expr: |
              rate(node_disk_io_time_seconds_total{job="node-exporter", device=~"(/dev/)?(mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|md.+|dasd.+)"}[5m])
            record: instance_device:node_disk_io_time_seconds:rate5m
          - expr: |
              rate(node_disk_io_time_weighted_seconds_total{job="node-exporter", device=~"(/dev/)?(mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|md.+|dasd.+)"}[5m])
            record: instance_device:node_disk_io_time_weighted_seconds:rate5m
          - expr: |
              sum without (device) (
                rate(node_network_receive_bytes_total{job="node-exporter", device!="lo"}[5m])
              )
            record: instance:node_network_receive_bytes_excluding_lo:rate5m
          - expr: |
              sum without (device) (
                rate(node_network_transmit_bytes_total{job="node-exporter", device!="lo"}[5m])
              )
            record: instance:node_network_transmit_bytes_excluding_lo:rate5m
          - expr: |
              sum without (device) (
                rate(node_network_receive_drop_total{job="node-exporter", device!="lo"}[5m])
              )
            record: instance:node_network_receive_drop_excluding_lo:rate5m
          - expr: |
              sum without (device) (
                rate(node_network_transmit_drop_total{job="node-exporter", device!="lo"}[5m])
              )
            record: instance:node_network_transmit_drop_excluding_lo:rate5m

      - name: grafana_rules
        rules:
          - expr: |
              sum by (namespace, job, handler, status_code) (rate(grafana_http_request_duration_seconds_count[5m]))
            record: namespace_job_handler_statuscode:grafana_http_request_duration_seconds_count:rate5m
